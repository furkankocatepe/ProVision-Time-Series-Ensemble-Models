{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal as mn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Setting the index to date\n",
    "    df = df.set_index('date')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.sort_index(inplace=True)\n",
    "   \n",
    "    df.dropna(inplace=True)\n",
    "    # Removing outliers\n",
    "    df = df[df['total_sales'] < df['total_sales'].quantile(0.95)]\n",
    "    df = df[df['total_revenue'] < df['total_revenue'].quantile(0.95)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for creating date features\n",
    "def create_date_features(df):\n",
    "    df = df.copy()\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['dayofmonth'] = df.index.day\n",
    "    df['weekofyear'] = df.index.isocalendar().week\n",
    "    df['weekofyear'] = df['weekofyear'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for creating lag features with 7, 14, 28, and 364 days\n",
    "# 364 days was chosen instead of 365 to make it the same day of week\n",
    "def create_lag_features(df, col):\n",
    "    lags = [7, 14, 28, 364]\n",
    "    for l in lags:\n",
    "        df[f'{col}_lag_{l}'] = df[col].shift(l)\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for creating rolling statistics features \n",
    "def create_rolling_features(df, target):\n",
    "    windows = [7, 14, 28, 364]\n",
    "    for w in windows:\n",
    "        df[f'rolling_mean_{w}'] = target.rolling(window=w).mean()\n",
    "        df[f'rolling_median_{w}'] = target.rolling(window=w).median()\n",
    "        df[f'rolling_min_{w}'] = target.rolling(window=w).min()\n",
    "        df[f'rolling_max_{w}'] = target.rolling(window=w).max()\n",
    "        df[f'rolling_std_{w}'] = target.rolling(window=w).std()\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, column):\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    encoded_features = ohe.fit_transform(df[[column]])\n",
    "\n",
    "    categories = ohe.categories_[0]\n",
    "    column_names = [f\"{column}_{category}\" for category in categories]\n",
    "    encoded_df = pd.DataFrame(encoded_features, columns=column_names)\n",
    "    \n",
    "    index = df.index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    encoded_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "    df.index = index\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor Model\n",
    "# Returns the model and predictions\n",
    "def model_rf(X, Y, training_size):\n",
    "    X = X.dropna()\n",
    "    Y = Y.dropna()\n",
    "    X_train, X_test = X[:training_size], X[training_size:]\n",
    "    Y_train, Y_test = Y[:training_size], Y[training_size:]\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    rf_fit = rf.fit(X_train, Y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    return rf_fit, rf_pred, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor Model\n",
    "# Returns the model and predictions\n",
    "def model_xgb_regressor(X,Y, training_size):\n",
    "    X = X.dropna()\n",
    "    Y = Y.dropna()\n",
    "    X_train, X_test = X[:training_size], X[training_size:]\n",
    "    Y_train, Y_test = Y[:training_size], Y[training_size:]\n",
    "    xgb = XGBRegressor(random_state = 42)\n",
    "    xgb_fit = xgb.fit(X_train, Y_train)\n",
    "    xgb_pred = xgb_fit.predict(X_test)\n",
    "    return xgb_fit, xgb_pred, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Regressor Model\n",
    "# Returns the model and predictions\n",
    "def model_lgbm_regressor(X,Y, training_size):\n",
    "    X = X.dropna()\n",
    "    Y = Y.dropna()\n",
    "    X_train, X_test = X[:training_size], X[training_size:]\n",
    "    Y_train, Y_test = Y[:training_size], Y[training_size:]\n",
    "    lgbm = LGBMRegressor(random_state=42)\n",
    "    lgbm_fit = lgbm.fit(X_train, Y_train)\n",
    "    lgbm_pred = lgbm.predict(X_test)\n",
    "    return lgbm_fit, lgbm_pred, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Regressor Model\n",
    "# Returns the model and predictions\n",
    "def model_ab_regressor(X,Y, training_size):\n",
    "    X = X.dropna()\n",
    "    Y = Y.dropna()\n",
    "    X_train, X_test = X[:training_size], X[training_size:]\n",
    "    Y_train, Y_test = Y[:training_size], Y[training_size:]\n",
    "    ab = AdaBoostRegressor(random_state=42)\n",
    "    ab_fit = ab.fit(X_train, Y_train)\n",
    "    ab_pred = ab.predict(X_test)\n",
    "    return ab_fit, ab_pred, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Regressor Model\n",
    "# Returns the model and predictions\n",
    "def model_catb_regressor(X,Y, training_size):\n",
    "    X = X.dropna()\n",
    "    Y = Y.dropna()\n",
    "    X_train, X_test = X[:training_size], X[training_size:]\n",
    "    Y_train, Y_test = Y[:training_size], Y[training_size:]\n",
    "    catb = CatBoostRegressor(random_state=42)\n",
    "    catb_fit = catb.fit(X_train, Y_train)\n",
    "    catb_pred = catb.predict(X_test)\n",
    "    return catb_fit, catb_pred, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for plotting predictions\n",
    "def plot_predictions(Y_test, predictions):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(predictions, Y_test, alpha=0.3)\n",
    "    plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Predictions')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries_pred(Y_train, Y_test, predictions):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(Y_train.index, Y_train, label='Train', color='green')\n",
    "    plt.plot(Y_test.index, Y_test, label='Test', color='red')\n",
    "    plt.plot(Y_test.index, predictions, label='Predicted', color='blue')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Target')\n",
    "    plt.title('Target Actual vs. Predicted')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating metrics\n",
    "# Returns metrics in a dataframe\n",
    "def get_metrics(Y_test, prediction):\n",
    "    rmse = mean_squared_error(Y_test, prediction, squared=False)\n",
    "    r2 = r2_score(Y_test, prediction)\n",
    "    metrics = pd.DataFrame([[rmse, r2]], columns=['RMSE', 'R2'])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe(features, target, train_size):\n",
    "    X_train, X_test = features[:train_size], features[train_size:]\n",
    "    Y_train, Y_test = target[:train_size], target[train_size:]\n",
    "    \n",
    "    models = [XGBRegressor(random_state=42), LGBMRegressor(random_state=42),\n",
    "          AdaBoostRegressor(random_state=42), CatBoostRegressor(random_state=42)]\n",
    "    model_names = ['XGBoost', 'LGBM', 'AdaBoost', 'CatBoost']\n",
    "\n",
    "    pipe_rmse = []\n",
    "    pipe_r2 = []\n",
    "    \n",
    "    for model in models:\n",
    "        pipe = Pipeline([\n",
    "            ('scaler', RobustScaler()),\n",
    "            ('models', model)\n",
    "        ])\n",
    "        \n",
    "        pipe.fit(X_train, Y_train)\n",
    "        pipe_pred = pipe.predict(X_test)\n",
    "        pipe_rmse.append(mean_squared_error(Y_test, pipe_pred, squared=False))\n",
    "        pipe_r2.append(r2_score(Y_test, pipe_pred))\n",
    "       \n",
    "    df_pipeline = pd.DataFrame({'Model': model_names, 'RMSE': pipe_rmse, 'R2': pipe_r2}).sort_values(by='RMSE')\n",
    "    return df_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_models(list_df_names, list_target_cols):\n",
    "    model_metrics = []\n",
    "    for df_name in list_df_names:\n",
    "        df = globals()[df_name].copy()\n",
    "        df = clean_data(df)\n",
    "        df = create_date_features(df)\n",
    "        for label in list_target_cols:\n",
    "            df = create_lag_features(df, label)\n",
    "            df = create_rolling_features(df, df[label])\n",
    "            \n",
    "            features = df.drop(list_target_cols, axis=1)\n",
    "            target = df[label]\n",
    "            train_s = round(len(df) * 0.80)\n",
    "            \n",
    "            df_pipeline = pipe(features, target, train_s)\n",
    "            \n",
    "            df_pipeline['DataFrame'] = df_name\n",
    "            df_pipeline['Target'] = label\n",
    "            model_metrics.append(df_pipeline)\n",
    "            print('model completed')\n",
    "    return model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
