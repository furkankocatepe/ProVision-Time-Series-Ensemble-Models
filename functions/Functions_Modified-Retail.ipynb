{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal as mn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Setting the index to date\n",
    "    df = df.set_index('date')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    # Removing outliers\n",
    "    df = df[df['total_sales'] < df['total_sales'].quantile(0.95)]\n",
    "    df = df[df['total_revenue'] < df['total_revenue'].quantile(0.95)]\n",
    "    \n",
    "    # Dropping object datatype columns\n",
    "    object_columns = df.dtypes[df.dtypes == 'object'].index\n",
    "    df.drop(object_columns, axis=1, inplace=True)\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for creating date features\n",
    "def create_date_features(df):\n",
    "    df = df.copy()\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['dayofmonth'] = df.index.day\n",
    "    df['weekofyear'] = df.index.isocalendar().week\n",
    "    df['weekofyear'] = df['weekofyear'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for creating lag features with 7, 14, 28, and 364 days\n",
    "# 364 days was chosen instead of 365 to make it the same day of week\n",
    "def create_lag_features(df, col):\n",
    "    lags = [7]\n",
    "    for l in lags:\n",
    "        df[f'{col}_lag_{l}'] = df[col].shift(l)\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for creating rolling statistics features \n",
    "def create_rolling_features(df, target):\n",
    "    windows = [7]\n",
    "    for w in windows:\n",
    "        df[f'rolling_mean_{w}'] = target.rolling(window=w).mean()\n",
    "        df[f'rolling_median_{w}'] = target.rolling(window=w).median()\n",
    "        df[f'rolling_min_{w}'] = target.rolling(window=w).min()\n",
    "        df[f'rolling_max_{w}'] = target.rolling(window=w).max()\n",
    "        df[f'rolling_std_{w}'] = target.rolling(window=w).std()\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, column):\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    encoded_features = ohe.fit_transform(df[[column]])\n",
    "\n",
    "    categories = ohe.categories_[0]\n",
    "    column_names = [f\"{column}_{category}\" for category in categories]\n",
    "    encoded_df = pd.DataFrame(encoded_features, columns=column_names)\n",
    "    \n",
    "    index = df.index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    encoded_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "    df.index = index\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for label encoding\n",
    "def label_encoder(column):\n",
    "    le = LabelEncoder()\n",
    "    label = le.fit_transform(column)\n",
    "    mapping = {index: label for index, label in enumerate(le.classes_)}\n",
    "    column = label\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_duplicates(df):\n",
    "    # Rename duplicate columns\n",
    "    cols=pd.Series(df.columns)\n",
    "    for dup in df.columns[df.columns.duplicated(keep=False)]: \n",
    "        cols[df.columns.get_loc(dup)] = ([dup + '.' + str(d_idx) \n",
    "                                        if d_idx != 0 \n",
    "                                        else dup \n",
    "                                        for d_idx in range(df.columns.get_loc(dup).sum())]\n",
    "                                        )\n",
    "\n",
    "    df.columns = cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_classifier_report(features, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "\n",
    "    models = [KNeighborsClassifier(3), SVC(kernel='rbf', gamma='auto', random_state=42), LGBMClassifier(random_state=42),\n",
    "            RandomForestClassifier(random_state=42), XGBClassifier(random_state=42), CatBoostClassifier(random_state=42)]\n",
    "\n",
    "    select = SelectFromModel(estimator=RandomForestClassifier(random_state=42))\n",
    "    scores = []\n",
    "    model_names = []\n",
    "\n",
    "    for model in models:\n",
    "        pipe = Pipeline([\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('feature selection', select),\n",
    "            ('models', model)\n",
    "        ])\n",
    "            \n",
    "        pipe.fit(X_train, y_train)\n",
    "        pipe.predict(X_test)\n",
    "        scores.append(pipe.score(X_test, y_test))\n",
    "        model_names.append(model.__class__.__name__)\n",
    "        \n",
    "    df_pipeline = pd.DataFrame({'Model': model_names, 'Accuracy': scores}).sort_values(by='Accuracy', ascending=False)\n",
    "    \n",
    "    return df_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_regressor(X_train, y_train, model):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    regressor = pipe.fit(X_train, y_train)\n",
    "    return regressor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_regressor_report(features, target, train_size):\n",
    "    X_train, X_test = features[:train_size], features[train_size:]\n",
    "    Y_train, Y_test = target[:train_size], target[train_size:]\n",
    "    \n",
    "    models = [XGBRegressor(random_state=42, n_jobs=-1), LGBMRegressor(random_state=42, n_jobs=-1),\n",
    "          RandomForestRegressor(random_state=42), CatBoostRegressor(random_state=42)]\n",
    "    model_names = ['XGBoost', 'LGBM', 'RF', 'CatBoost']\n",
    "\n",
    "    rmse = []\n",
    "    r2 = []\n",
    "    \n",
    "    for model in models:\n",
    "        pipe = Pipeline([\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('models', model)\n",
    "        ])\n",
    "        \n",
    "        pipe.fit(X_train, Y_train)\n",
    "        pipe_pred = pipe.predict(X_test)\n",
    "        rmse.append(mean_squared_error(Y_test, pipe_pred, squared=False))\n",
    "        r2.append(r2_score(Y_test, pipe_pred))\n",
    "       \n",
    "    df_pipeline = pd.DataFrame({'Model': model_names, 'RMSE': rmse, 'R2': r2}).sort_values(by='RMSE')\n",
    "    return df_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_models(list_df_names, list_target_cols):\n",
    "    model_metrics = []\n",
    "    for df_name in list_df_names:\n",
    "        df = globals()[df_name].copy()\n",
    "        df = clean_data(df)\n",
    "        df = create_date_features(df)\n",
    "        for label in list_target_cols:\n",
    "            df = create_lag_features(df, label)\n",
    "            df = create_rolling_features(df, df[label])\n",
    "            \n",
    "            features = df.drop(list_target_cols, axis=1)\n",
    "            target = df[label]\n",
    "            train_s = round(len(df) * 0.80)\n",
    "            \n",
    "            df_pipeline = pipe(features, target, train_s)\n",
    "            \n",
    "            df_pipeline['DataFrame'] = df_name\n",
    "            df_pipeline['Target'] = label\n",
    "            model_metrics.append(df_pipeline)\n",
    "            print('model completed')\n",
    "    return model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries_pred(Y_train, Y_test, predictions):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(Y_train.index, Y_train, label='Train', color='green')\n",
    "    plt.plot(Y_test.index, Y_test, label='Test', color='red')\n",
    "    plt.plot(Y_test.index, predictions, label='Predicted', color='blue')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Target')\n",
    "    plt.title('Target Actual vs. Predicted')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating metrics\n",
    "# Returns metrics in a dataframe\n",
    "def get_metrics(Y_test, prediction):\n",
    "    rmse = mean_squared_error(Y_test, prediction, squared=False)\n",
    "    r2 = r2_score(Y_test, prediction)\n",
    "    metrics = pd.DataFrame([[rmse, r2]], columns=['RMSE', 'R2'])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
